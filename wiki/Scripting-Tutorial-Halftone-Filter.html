<!DOCTYPE html>
<html lang="en" dir="ltr">


<!-- Mirrored from obsproject.com/wiki/Scripting-Tutorial-Halftone-Filter by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 31 Dec 2023 03:57:04 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
  <title>Wiki - Scripting Tutorial Halftone Filter | OBS</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
      <meta name="description" content="This tutorial describes the implementation of a "halftone" filter as a Lua script for OBS. Such a filter appears in the list of filters and can be added as part of a filter chain …">
    <meta name="keywords" content="OBS, OBS Studio, Stream, Video, Live Streaming, Recording, Games, Twitch, YouTube, Livestream, Open Broadcaster Software">
    <!--<link rel="preload" href="/assets/fonts/open-sans-v18-latin-ext_latin_cyrillic-regular.woff2" as="font" type="font/woff2" crossorigin>-->
  <link href="https://obsproject.com/assets/css/blurple.min.css?20230116-1" rel="stylesheet">    <link rel="alternate" type="application/rss+xml" title="RSS Feed obsproject.com" href="https://obsproject.com/blog/rss">
  <link rel="icon" type="image/png" sizes="32x32" href="https://obsproject.com/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="https://obsproject.com/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="https://obsproject.com/favicon-16x16.png">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-34644124-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-34644124-1', {
      'anonymize_ip': true
    });
  </script>
</head>

<body class="">

  <div id="wrapper">

    <header id="header" class="cf">
      <a class="logo" href="https://obsproject.com/">
        <img src="https://obsproject.com/assets/images/new_icon_small-r.png" alt="OBS" />
      </a>

      <div class="header_title">
        <div class="header_title_main">OBS</div>
        <div class="header_subtitle">Open Broadcaster Software<span class="smalltext">®️</span></div>
      </div>

      <div id="SocialButtons">

        <div id="DiscordButton">
          <a href="https://discord.gg/obsproject" target="_blank" aria-label="OBS Discord">
            <img src="https://obsproject.com/assets/images/Discord.svg" class="icon-discord" />
          </a>
          <span class="tooltip">Discord</span>
        </div>

        <div id="TwitterButton">
          <a rel="me" href="https://twitter.com/OBSProject" target="_blank" aria-label="OBS Twitter">
            <i class="icon-twitter"></i>
          </a>
          <span class="tooltip">Twitter</span>
        </div>

        <div id="MastodonButton">
          <a rel="me" href="https://mastodon.social/@OBSProject" target="_blank" aria-label="OBS Mastodon">
            <img src="https://obsproject.com/assets/images/Mastodon.svg" class="icon-mastodon">
          </a>
          <span class="tooltip">Mastodon</span>
        </div>

        <div id="GitHubButton">
          <a rel="me" href="https://github.com/obsproject/obs-studio" target="_blank" aria-label="OBS Studio GitHub">
            <i class="icon-github"></i>
          </a>
          <span class="tooltip">GitHub</span>
        </div>
        <!--
          <div id="BlogButton">
            <a href="https://obsproject.com/blog">
              <i class="icon-blog"></i>
            </a>
          </div>

          <div id="LivechatButton">
            <a href="https://obsproject.com/chat" target="_blank">
              <i class="icon-comment">Community Chat</i>
            </a>
          </div>
        -->

        <div id="ContributeButton">
          <a href="https://obsproject.com/contribute">
            <i class="icon-heart">Contribute</i>
          </a>
        </div>

      </div>

      <nav>

  <ul class="menu cf">
          <li>
                <a  href="https://obsproject.com/">Home</a>

        
      </li>
          <li>
                <a  href="https://obsproject.com/download">Download</a>

        
      </li>
          <li>
                <a  href="https://obsproject.com/blog">News</a>

        
      </li>
          <li>
                <a  href="https://obsproject.com/help">Help</a>

        
      </li>
          <li>
                <a  href="https://obsproject.com/forum/">Forum</a>

        
      </li>
      </ul>

</nav>
    </header><!-- Debug2 -->
<div class="pagewidth wiki_container">

	<div class="headerpusher"></div>

	<div class="full_width wiki_header">
		<h1>Scripting Tutorial Halftone Filter</h1>
	</div>

	<div class="wiki_content">
		<p>This tutorial describes the implementation of a "halftone" filter as a Lua script for OBS. Such a filter appears in the list of filters and can be added as part of a filter chain to any video source. As effect, the filter mimics the <a href="https://en.wikipedia.org/wiki/Halftone">halftone technique</a>, used for printing with a reduced set of ink colors arranged in patterns. It is based on <a href="https://en.wikipedia.org/wiki/Dither">dithering</a> with a carefully designed texture.</p>
<p><a id='first-part---4-shades-of-grey' class='anchor' aria-hidden='true'></a></p>
<h2>First part - 4 Shades of Grey</h2>
<p>The tutorial is divided into two parts. In this first part, we create a minimal script that implements a simple rendering effect. Such a script with its effect file can be easily re-used as starting point for new projects.</p>
<p><a id='script-creation' class='anchor' aria-hidden='true'></a></p>
<h3>Script creation</h3>
<p>Similarly to the <a href="https://obsproject.com/wiki/Scripting-Tutorial-Source-Shake">Source Shake tutorial</a>, create a script file named <code>filter-halftone.lua</code> with this content:</p>
<pre><code class="language-Lua">obs = obslua

-- Returns the description displayed in the Scripts window
function script_description()
  return [[Halftone Filter
  This Lua script adds a video filter named Halftone. The filter can be added
  to a video source to reduce the number of colors of the input picture. It reproduces
  the style of a magnified printed picture.]]
end</code></pre>
<p>Add the new script in the <em>Scripts</em> window, the description should appear (with no properties).</p>
<p><a id='registering-a-first-source-info-structure' class='anchor' aria-hidden='true'></a></p>
<h3>Registering a first source info structure</h3>
<p>Sources are supported in Lua through the <a href="https://obsproject.com/docs/scripting.html#script-sources-lua-only"><code>source_info</code> structure</a>. It is defined as a usual Lua table containing a set of mandatory keys referencing values and functions that mimic a subset of the <a href="https://obsproject.com/docs/reference-sources.html?highlight=source_info#c.obs_source_info">C <code>obs_source_info</code> structure</a>.</p>
<p>The <code>source_info</code> structure is registered using <a href="https://obsproject.com/docs/reference-sources.html#c.obs_register_source"><code>obs_register_source</code></a>. OBS will use the structure to create the internal data and settings when the filter is added to an existing video source. A filter has its own independent set of properties and data settings, i.e. an instance of such settings exists for each filter instance. OBS manages the filter creation, destruction and the persistent storage of its settings.</p>
<p>Let's create the source info structure for a video filter with a minimal set of values and functions. It is typically registered in <code>script_load</code>:</p>
<pre><code class="language-Lua">-- Called on script startup
function script_load(settings)
  obs.obs_register_source(source_info)
end

-- Definition of the global variable containing the source_info structure
source_info = {}
source_info.id = 'filter-halftone'              -- Unique string identifier of the source type
source_info.type = obs.OBS_SOURCE_TYPE_FILTER   -- INPUT or FILTER or TRANSITION
source_info.output_flags = obs.OBS_SOURCE_VIDEO -- Combination of VIDEO/AUDIO/ASYNC/etc

-- Returns the name displayed in the list of filters
source_info.get_name = function()
  return "Halftone"
end</code></pre>
<p>Add the code, refresh the script, then choose a source (here a colorful picture of the VR game Anceder) and display the <em>Filter</em> dialog window for the source (e.g. <em>Filters</em> in the context menu of the source). Click on + and the name <em>Halftone</em> should appear in the list of filters:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-list.png" alt="filter halftone list" /></p>
<p>Add the new <em>Halftone</em> filter. For now the filter has no effect because the <code>source_info.create</code> function is not defined.</p>
<p><a id='effect-compilation-and-rendering' class='anchor' aria-hidden='true'></a></p>
<h3>Effect compilation and rendering</h3>
<p>Lua would not be fast enough for video processing so the filter is based on GPU computation. A GPU can be programmed through "shaders" compiled by the graphics device driver from <a href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">GLSL</a> for OpenGL or <a href="https://en.wikipedia.org/wiki/High-Level_Shading_Language">HLSL</a> in the MS Windows world. OBS relies on HLSL and expects shader code in the so-called <a href="https://obsproject.com/docs/graphics.html">effect files</a>.</p>
<p>An effect can be compiled from a file with <a href="https://obsproject.com/docs/reference-libobs-graphics-effects.html#c.gs_effect_create_from_file"><code>gs_effect_create_from_file</code></a> or from a string with <a href="https://obsproject.com/docs/reference-libobs-graphics-effects.html#c.gs_effect_create"><code>gs_effect_create</code></a>, and is destroyed with <a href="https://obsproject.com/docs/reference-libobs-graphics-effects.html#c.gs_effect_destroy"><code>gs_effect_destroy)</code></a>. Like other graphic functions in OBS, manipulating effects needs to occur in the <a href="https://obsproject.com/docs/graphics.html#the-graphics-context">graphics context</a>. This is ensured by calling <a href="https://obsproject.com/docs/reference-core.html#c.obs_enter_graphics"><code>obs_enter_graphics</code></a> and then <a href="https://obsproject.com/docs/reference-core.html#c.obs_leave_graphics"><code>obs_leave_graphics</code></a> when everything is done.</p>
<p>The compilation is typically implemented in the <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_info.create"><code>source_info.create</code></a> function and resources are released in the <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_info.destroy"><code>source_info.destroy</code></a> function. <code>source_info.create</code> returns a Lua table containing custom data used for the filter instance. Most functions of the <code>source_info</code> structure will provide this Lua table passed as an argument, so this is where you want to store any custom data needed by the filter. Please note that if <code>source_info.create</code> returns <code>nil</code>, then the filter initialization is considered failed (and logged accordingly).</p>
<p>Add this code to the Lua script:</p>
<pre><code class="language-Lua">-- Creates the implementation data for the source
source_info.create = function(settings, source)

  -- Initializes the custom data table
  local data = {}
  data.source = source -- Keeps a reference to this filter as a source object
  data.width = 1       -- Dummy value during initialization phase
  data.height = 1      -- Dummy value during initialization phase

  -- Compiles the effect
  obs.obs_enter_graphics()
  local effect_file_path = script_path() .. 'filter-halftone.effect.hlsl'
  data.effect = obs.gs_effect_create_from_file(effect_file_path, nil)
  obs.obs_leave_graphics()

  -- Calls the destroy function if the effect was not compiled properly
  if data.effect == nil then
    obs.blog(obs.LOG_ERROR, "Effect compilation failed for " .. effect_file_path)
    source_info.destroy(data)
    return nil
  end

  return data
end

-- Destroys and release resources linked to the custom data
source_info.destroy = function(data)
  if data.effect ~= nil then
    obs.obs_enter_graphics()
    obs.gs_effect_destroy(data.effect)
    data.effect = nil
    obs.obs_leave_graphics()
  end
end</code></pre>
<p>The effect file <code>filter-halftone.effect.hlsl</code> is mentioned in the code, it will defined in the next section. Please note that the <code>source</code> argument of the function <code>source_info.create</code> is a reference to the current instance of the filter as a source object (almost everything is a source in OBS). This reference, as well as the variables <code>width</code> and <code>height</code>, initialized with dummy values, are used in the rendering function.</p>
<p>Namely, the function <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_info.video_render"><code>source_info.video_render</code></a> is called each frame to render the output of the filter in the graphics context (no need to call <code>obs_enter_graphics</code>). To render an effect, first <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_process_filter_begin"><code>obs_source_process_filter_begin</code></a> is called, then the effect parameters can be set, and then <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_process_filter_end"><code>obs_source_process_filter_end</code></a> is called to draw.</p>
<p>Determining the width and height to pass to <code>obs_source_process_filter_end</code> is somehow tricky in OBS, because the filter is itself in a chain of filters, where the resolution could theoretically change at any stage. The usual method is to retrieve the "parent source" of the filter with <a href="https://obsproject.com/docs/reference-sources.html#c.obs_filter_get_parent"><code>obs_filter_get_parent</code></a>, i.e. "the source being filtered", and then to use the so far undocumented functions <code>obs_source_get_base_width</code> and <code>obs_source_get_base_height</code>. Note that some filters reference the next source in the chain using <code>obs_filter_get_target</code>, not the source being filtered (it may make a difference depending on the use case).</p>
<p>In addition, two additional functions <code>source_info.get_width</code> and <code>source_info.get_height</code> must be defined to provide the values to OBS whenever necessary. The functions will re-use the values determined in <code>source_info.video_render</code>.</p>
<p>The effect rendering code looks like:</p>
<pre><code class="language-Lua">-- Returns the width of the source
source_info.get_width = function(data)
  return data.width
end

-- Returns the height of the source
source_info.get_height = function(data)
  return data.height
end

-- Called when rendering the source with the graphics subsystem
source_info.video_render = function(data)
  local parent = obs.obs_filter_get_parent(data.source)
  data.width = obs.obs_source_get_base_width(parent)
  data.height = obs.obs_source_get_base_height(parent)

  obs.obs_source_process_filter_begin(data.source, obs.GS_RGBA, obs.OBS_NO_DIRECT_RENDERING)

  -- Effect parameters initialization goes here

  obs.obs_source_process_filter_end(data.source, data.effect, data.width, data.height)
end</code></pre>
<p>Add the code blocks to the Lua script, but no need to reload for now, the effect file is still missing.</p>
<p><a id='simple-hlsl-luminance-effect-file' class='anchor' aria-hidden='true'></a></p>
<h3>Simple HLSL luminance effect file</h3>
<dl>
<dt>The Lua code is in place, now create a new file called <code>filter-halftone.effect.hlsl</code> in the same directory as the Lua script.</dt>
<dd>
<p>warning: The extension <code>.hlsl</code> is chosen such that a code editor or an IDE recognizes directly that it is HLSL code. As the parser of OBS may miss unbalanced brackets or parenthesis (and say nothing about it in the logs), it is very important to have syntax checking in the editor.</p>
</dd>
</dl>
<p>An <a href="https://docs.microsoft.com/en-us/windows/win32/direct3d11/d3d11-effect-format">effect file</a> follows a strict syntax and structure. It is a mix of static data definitions and code. These constraints are necessary to allow the compilation for the GPU and the massively parallel execution. The various parts are described below.</p>
<p>Our effect file starts with macro definitions that will allow writing HLSL-compliant code instead of the effect dialect understood by OBS, in order to support a full syntax check in the IDE. Indeed, the keywords <code>sampler_state</code> and <code>texture2d</code> are specific to effects in OBS. Using such macros is of course not mandatory (and not so common looking at other OBS effect files):</p>
<pre><code class="language-HLSL">// OBS-specific syntax adaptation to HLSL standard to avoid errors reported by the code editor
#define SamplerState sampler_state
#define Texture2D texture2d</code></pre>
<p>Then the two mandatory <code>uniform</code> parameters required by OBS are defined. The values of these parameters will be set transparently by OBS according to the input picture of the source being filtered set in <code>image</code>, and the "View-Projection Matrix" <code>ViewProj</code> used to compute the screen coordinates where the filtered picture will be drawn:</p>
<pre><code class="language-HLSL">// Uniform variables set by OBS (required)
uniform float4x4 ViewProj; // View-projection matrix used in the vertex shader
uniform Texture2D image;   // Texture containing the source picture</code></pre>
<p>The next definition is a "<a href="https://docs.microsoft.com/en-us/windows/win32/api/d3d11/ns-d3d11-d3d11_sampler_desc">sampler state</a>". It defines how to sample colors from pixels in a texture, i.e. how to interpolate colors between two pixels (Linear) or just to take the next neighbor (Point), and how to behave in the the pixel coordinates are outside of the texture, i.e. take the pixels from the nearest edge (Clamp), wrap around (Wrap) or mirror the texture over the edges (Mirror). The <a href="https://obsproject.com/docs/graphics.html#effect-sampler-states">supported values for sampler states</a> are documented in the OBS API reference.</p>
<p>We define a simple linear clamp sampler state that will be used in the pixel shader:</p>
<pre><code class="language-HLSL">// Interpolation method and wrap mode for sampling a texture
SamplerState linear_clamp
{
    Filter    = Linear;     // Anisotropy / Point / Linear
    AddressU  = Clamp;      // Wrap / Clamp / Mirror / Border / MirrorOnce
    AddressV  = Clamp;      // Wrap / Clamp / Mirror / Border / MirrorOnce
    BorderColor = 00000000; // Used only with Border edges (optional)
};</code></pre>
<p>After that, two very specific data structures are defined to specify which parameters are given to the vertex shader, and passed from the vertex shader to the pixel shader. In this tutorial these structures are artificially separated for better understanding and more generality. In most effects, both structures are defined in only one structure.</p>
<p>The structures require for each parameter a <a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-semantics">semantics</a> identifier giving the intended use of the parameter. <a href="https://obsproject.com/docs/graphics.html#effect-vertex-pixel-semantics">Supported semantics</a> are documented in the OBS API reference. Semantics are necessary for the graphics pipeline of the GPU:</p>
<pre><code class="language-HLSL">// Data type of the input of the vertex shader
struct vertex_data
{
    float4 pos : POSITION;  // Homogeneous space coordinates XYZW
    float2 uv  : TEXCOORD0; // UV coordinates in the source picture
};

// Data type of the output returned by the vertex shader, and used as input 
// for the pixel shader after interpolation for each pixel
struct pixel_data
{
    float4 pos : POSITION;  // Homogeneous screen coordinates XYZW
    float2 uv  : TEXCOORD0; // UV coordinates in the source picture
};</code></pre>
<p>Before going further, some words about the classical 3D rendering pipeline. Roughly speaking, it comprises these main steps:</p>
<ul>
<li>The application, here OBS, set-ups all data structures (textures, data parameters, arrays, etc) necessary for the computation and then feeds the 3D coordinates of triangles into the vertex shader together with various vertex attributes such as UV coordinate of the vertex mapped to a texture or a color assigned to this vertex, all part of the <code>vertex_data</code> structure.</li>
<li>Each time a <code>vertex_data</code> structure is available in the GPU, the <em>vertex shader</em> is called and returns a <code>pixel_data</code> structure corresponding to the pixel under the vertex as seen on the screen. During this call, the vertex shader transforms the 3D world coordinates of the vertex into screen coordinates, and transforms the other vertex attributes if necessary.</li>
<li>Then many complex steps are performed by the GPU to determine how far the surface of each triangle is visible on the screen, up to each visible pixel.</li>
<li>Each time the GPU determines that a pixel of a triangle is visible, it calls the <em>pixel shader</em> with a <code>pixel_data</code> structure as argument that corresponds to the position of the pixel. In order to provide position-specific values for each pixel of the triangle, the GPU interpolates values from the values of the 3 structures returned for the 3 vertices of the triangle by the vertex shader.</li>
</ul>
<p>To render sources, OBS follows the same model and renders simply quads (2 triangles) on the screen, where each vertex has the UV mapping of the source picture as attribute. The vertex shader is only used to compute the screen coordinates of the 4 vertices of the quad, according to the transform of the source, and to pass the UV coordinates to the pixel shader. The classical method for the transformation of world coordinates into screen coordinates is a <a href="http://www.it.hiof.no/~borres/j3d/math/threed/p-threed.html">multiplication through the "View-Projection" 4x4 matrix in homogeneous coordinates</a> (don't be afraid, it is not necessary to understand homogeneous coordinates for the tutorial):</p>
<pre><code class="language-HLSL">// Vertex shader used to compute position of rendered pixels and pass UV
pixel_data vertex_shader_halftone(vertex_data vertex)
{
    pixel_data pixel;
    pixel.pos = mul(float4(vertex.pos.xyz, 1.0), ViewProj);
    pixel.uv  = vertex.uv;
    return pixel;
}</code></pre>
<p>The vertex shader will remain like this in most cases with OBS. Altering the 3D transformation would change the proper location of displayed sources on the screen. Note that interesting results could be achieved, e.g. actually the Source Shake animation could be certainly implemented as a smart modification of the View-Projection matrix.</p>
<p>Please note the well-adapted HLSL syntax <code>vertex.pos.xyz</code> here. <code>pos</code> is a <code>vertex</code> member with vector type <code>float4</code>. Adding the suffix <code>.xyz</code> is sufficient to convert it to a temporary <code>float3</code> vector with the values of the components <code>x</code>, <code>y</code> and <code>z</code> of <code>pos</code>. Then <code>float4(vertex.pos.xyz, 1.0)</code> is again a <code>float4</code> vector with the 3 first components of <code>vertex.pos.xyz</code> and <code>1.0</code> as fourth component. The HLSL syntax, which is by the way very similar to GLSL used in OpenGL, has this special feature that makes it very compact for matrix and vector operations.</p>
<p>Now the real heart of the video filter effect is in the Pixel Shader. The main principle of a pixel shader is very simple: this is a function that computes a color at a given pixel position. The pixel shader function is called for every single pixel within the draw area.</p>
<p>As a simple gray shading effect, we want to compute the "luminance" of the source pixel (i.e. its brightness or luminous intensity), and use it for each RGB component of the output color:</p>
<pre><code class="language-HLSL">// Pixel shader used to compute an RGBA color at a given pixel position
float4 pixel_shader_halftone(pixel_data pixel) : TARGET
{
    float4 source_sample = image.Sample(linear_clamp, pixel.uv);
    float luminance = dot(source_sample.rgb, float3(0.299, 0.587, 0.114));
    return float4(luminance.xxx, source_sample.a);
}</code></pre>
<p>Please again admire the incredibly compact syntax:</p>
<ul>
<li>On the first line, the <code>source_sample</code> variable receives the RGBA color of the pixel at <code>pixel.uv</code> in the source picture in UV coordinates, following a sampling method given by <code>linear_clamp</code>. Attention: here <code>.uv</code> is just a <code>float2</code> member of the structure <code>pixel</code>, not a suffix to access particular vector components.</li>
<li>On the second line, the <a href="https://en.wikipedia.org/wiki/Relative_luminance">relative luminance</a> is computed as a <a href="https://en.wikipedia.org/wiki/Dot_product">dot product</a> of the <code>float3</code> vector of the RGB components of <code>sample_color</code> and the constant <code>float3</code> vector <em>(0.299, 0.587, 0.114)</em>. The expression is equivalent to <code>source_sample.r*0.299 + source_sample.g*0.587 + source_sample.b*0.114</code>. Suffices <code>r</code>, <code>g</code>, <code>b</code>, <code>a</code> can be used like <code>x</code>, <code>y</code>, <code>z</code>, <code>w</code> to access particular vector components. It is necessary to write <code>source_sample.rgb</code> here because it is a <code>float4</code> vector and we want to exclude the <code>a</code> component from the dot product.</li>
<li>On the third line, a <code>float4</code> vector is built with three time the <code>luminance</code> value and then the original alpha value of the source color as fourth component. The color is returned as a <code>float4</code> containing the values of the RGBA components between 0.0 and 1.0.</li>
</ul>
<p>The position of the pixel is provided through the <code>pixel_data</code> structure:</p>
<ul>
<li><code>pixel.pos</code> is a <code>float4</code> vector resulting from the computation in the vertex shader and further interpolation. In the pixel shader <code>pixel.pos.xy</code> may contain the absolute position on screen of the pixel being rendered (i.e. values change if the user moves the source with the mouse). Now if the source is itself scaled with a setting of <em>Scale filtering</em> different than <em>Disable</em>, or if some other filter needs to render in a texture as an intermediate step, then <code>pixel.pos.xy</code> may contain some other pixel coordinates corresponding to the internal texture used to render the output of our filter before further processing. In addition, as <code>pixel.pos</code> is in homogeneous coordinates, normally it is necessary to divide <code>x</code> and <code>y</code> by the <code>w</code> components (which should be always equal to 1 here as there is no 3D). Long story short, it is not recommended to use <code>pixel.pos</code> directly.</li>
<li><code>pixel.uv</code> gives the interpolated UV coordinates of the pixel in the source picture as a <code>float2</code> vector, i.e. it does not depend on the position or scaling of the source. As UV coordinates, <code>pixel.uv.x</code> and <code>pixel.uv.y</code> have values in range 0.0 to 1.0, with the upper left corner of the source picture is at position (0.0,0.0) and the bottom right corner at (1.0,1.0). This is what we want to use to reference the source pixels. In addition, the UV coordinates can be used directly to retrieve the pixel color from the <code>image</code> texture.</li>
</ul>
<p>The final part of the effect file is the definition of the "techniques". Here again the structure will be similar in most effects, typically with one pass and one technique:</p>
<pre><code class="language-HLSL">technique Draw
{
    pass
    {
        vertex_shader = vertex_shader_halftone(vertex);
        pixel_shader  = pixel_shader_halftone(pixel);
    }
}</code></pre>
<p>Add all the code blocks in the HLSL file, then restart OBS, normally the source should be displayed in black and white:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-luminance.png" alt="filter halftone luminance" /></p>
<p>Well, this is not really a halftone picture here, but it clearly shows the expected shades of gray according to the luminance. The example picture is very dark and needs some luminosity correction.</p>
<p><a id='gamma-correction' class='anchor' aria-hidden='true'></a></p>
<h3>Gamma correction</h3>
<p>Colors are typically encoded with 8 bits for each RGB component, i.e. in range 0 to 255, corresponding to the range 0.0 to 1.0 in HLSL. But because the human eye has a <a href="http://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/">non-linear perception of the light intensity</a> emitted by the monitor, usually the values encoded in RGB components do not grow linearly with the intensity, they follow a power law with an exponent called "gamma". This non-linearity of the RGB components can be a problem in a video filter if some computation is performed assuming components are encoded in a linear way.</p>
<p>Actually, in the frame of an OBS filter, this is not always an issue. Some sources will provide linearized pixel data to the shaders, some others will provide gama-encoded data. As of version 26.1, several attempts were made to have consistently linearized colors available in shaders. As long as it is not fully implemented, to give the maximum flexibility, we will to let the user select if the source is gamma-encoded or not. As the filter of this tutorial is more artistic than exact, a user would just try different settings to get the best result.</p>
<p>The power law for encoding and decoding uses typically an exponent <em>2.2</em> or <em>1/2.2</em>. The two operations of <a href="https://en.wikipedia.org/wiki/gamma_correction">gamma correction</a> are called first <em>gamma compression</em>, i.e. encoding of an RGB component proportional to the light intensity into a value to be displayed to a human eye, with an exponent lower than 1, and <em>gamma expansion</em> with an exponent greater than 1.</p>
<p>Let's call <em>gamma</em> the exponent used for color decoding (greater than 1) with a value of <em>2.2</em>. We can use simplified formulas for gamma encoding:</p>
<p>_encoded_value = linear<em>value 1/gamma</em></p>
<p>And for gamma decoding:</p>
<p>_linear_value = encoded<em>value gamma</em></p>
<p>Please note that such formulas keep values nicely between 0.0 and 1.0.</p>
<p>Now to come back to the halftone filter, we noted that the example picture is a bit too dark, and we know that changing the "gamma" of a picture change its overall luminosity. So we can introduce a gamma computation for 2 purposes: use of linear values for more exact calculations and a "gamma shift" of the source picture (not called "gamma correction" to avoid misunderstandings).</p>
<p>Namely, a gamma decoding including a subtractive shift would look like this, performed <em>before</em> any computation on the RGB color components (with a minus such that positive values increase the luminosity):</p>
<p>_linear_value = encoded<em>value gamma-shift</em></p>
<p>Let's do it in the code, starting with the definition of the <code>gamma</code> and <code>gamma_shift</code> uniform variables and default values with other uniform variables at the top of the HLSL effect file:</p>
<pre><code class="language-HLSL">// General properties
uniform float gamma = 1.0;
uniform float gamma_shift = 0.6;</code></pre>
<p>Experiment and adapt the default values of <code>gamma</code> and <code>gamma_shift</code> to your source. They will be defined through OBS properties later on.</p>
<p>We introduce the gamma encoding and decoding functions, and re-write the pixel shader to use it. We use an additional <code>clamp</code> function to be sure to keep values between 0.0 and 1.0 before the exponentiation. In fact this may not be necessary but it avoids a warning that may be produced by the compiler. Add the code below the vertex shader:</p>
<pre><code class="language-HLSL">float3 decode_gamma(float3 color, float exponent, float shift)
{
    return pow(clamp(color, 0.0, 1.0), exponent - shift);
}

float3 encode_gamma(float3 color, float exponent)
{
    return pow(clamp(color, 0.0, 1.0), 1.0/exponent);
}

// Pixel shader used to compute an RGBA color at a given pixel position
float4 pixel_shader_halftone(pixel_data pixel) : TARGET
{
    float4 source_sample = image.Sample(linear_clamp, pixel.uv);
    float3 linear_color = decode_gamma(source_sample.rgb, gamma, gamma_shift);

    float luminance = dot(linear_color, float3(0.299, 0.587, 0.114));
    float3 result = luminance.xxx;

    return float4(encode_gamma(result, gamma), source_sample.a);
}</code></pre>
<p>Add all the code blocks in the HLSL file, then <em>restart OBS</em> (only reloading the script would not help, because the effect remains cached and would not be re-compiled). Depending on the values you select for <code>gamma</code> and <code>gamma_shift</code>, the filtered picture should have a different overall luminosity:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-gamma-corrected-luminance.png" alt="filter halftone gamma corrected luminance" /></p>
<p>The picture is a bit better now.</p>
<p><a id='width-and-height-from-lua-to-the-shader' class='anchor' aria-hidden='true'></a></p>
<h3>Width and height from Lua to the shader</h3>
<p>Whatever the final form, the halftone effect is based on a pattern applied pixel-by-pixel to the source picture. While it is easy to transform the color of a single pixel, if the position of the pixel is necessary to recognize in which part of a pattern the pixel is located, then the UV coordinates alone are not sufficient in the general case, it is necessary to know the size of the source picture. More about the calculations in the next section.</p>
<p>In this section we will first see how to make the values of <code>width</code> and <code>height</code> available in the shader from the Lua code. Strangely, OBS does not foresee these parameters in effect files by default. We define the <code>uniform</code> variables with other uniform variables at the top of the HLSL effect file:</p>
<pre><code class="language-HLSL">// Size of the source picture
uniform int width;
uniform int height;</code></pre>
<p>Only uniform variables can be changed from the Lua code. Once an effect is compiled, the function <a href="https://obsproject.com/docs/reference-libobs-graphics-effects.html#c.gs_effect_get_param_by_name"><code>gs_effect_get_param_by_name</code></a> provides the necessary <code>gs_eparam</code> structure where the value can be set.</p>
<p>The effect parameters can be retrieved at the end of the <code>source_info.create</code> in the Lua file (above <code>return data</code>):</p>
<pre><code class="language-Lua">  -- Retrieves the shader uniform variables
  data.params = {}
  data.params.width = obs.gs_effect_get_param_by_name(data.effect, "width")
  data.params.height = obs.gs_effect_get_param_by_name(data.effect, "height")</code></pre>
<p>Finally the values are set with <a href="https://obsproject.com/docs/reference-libobs-graphics-effects.html#c.gs_effect_set_int"><code>gs_effect_set_int</code></a> between <code>obs_source_process_filter_begin</code> and <code>obs_source_process_filter_end</code> in in <code>source_info.video_render</code>:</p>
<pre><code class="language-Lua">  -- Effect parameters initialization goes here
  obs.gs_effect_set_int(data.params.width, data.width)
  obs.gs_effect_set_int(data.params.height, data.height)</code></pre>
<p>Add the code, restart OBS, for now no difference is expected, the interesting things start in the next section.</p>
<p><a id='luminance-perturbation' class='anchor' aria-hidden='true'></a></p>
<h3>Luminance perturbation</h3>
<p>Now that the size of the picture is available, we can start to use pixel coordinates for formulas. Namely, we want to add a little perturbation on the computed luminance according to the formula <em>cos(x)*cos(y)</em>. The form of this classic formula looks like:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-perturbation-curve.png" alt="filter halftone " /></p>
<p>The formula will be such that:</p>
<ul>
<li>It adds to the luminance a small negative or positive value with a given amplitude</li>
<li>The scale of the form can be changed, with a scale of 1.0 corresponding to a 8 pixels long oscillation</li>
</ul>
<p>If we name the parameters of the formula simply <em>scale</em> and <em>amplitude</em>, assuming <em>x</em> and <em>y</em> are in pixels, the angle for the oscillations on <em>x</em> is given by <em>2*&pi;*x/scale/8</em> (the bigger the <em>scale</em>, the longer the oscillations). The cosine function returns values between -1.0 and 1.0, so the <em>amplitude</em> can be just multiplied to the product of cosine.</p>
<p>The final parameterized formula will be (with simplification):</p>
<p><em>perturbation = amplitude*cos(&pi;*x/scale/4)*cos(&pi;*y/scale/4)</em></p>
<p>For the coordinates <em>x</em> and <em>y</em> in pixels, as we have the <em>width</em> and <em>height</em> plus the UV coordinates, the formula are simply <em>x = U * width</em> and <em>y = V * height</em> if we call the UV coordinates <em>U</em> and <em>V</em> here. In the code, we will use a more compact form with a component-by-component multiplication of <code>pixel.uv</code> with <code>float2(width,height)</code>.</p>
<p>Re-write the center part of the pixel shader (between the decoding and encoding lines) in the HLSL effect file:</p>
<pre><code class="language-HLSL">    float luminance = dot(linear_color, float3(0.299, 0.587, 0.114));
    float2 position = pixel.uv * float2(width, height);
    float perturbation = amplitude * cos(PI*position.x/scale/4.0) * cos(PI*position.y/scale/4.0);
    float3 result = (luminance + perturbation).xxx;</code></pre>
<p>At the top of the file, do not forget to define a new constant for <code>PI</code> and the new uniform variables <code>scale</code> and <code>amplitude</code> with default values:</p>
<pre><code class="language-HLSL">// Constants
#define PI 3.141592653589793238

// General properties
uniform float amplitude = 0.2;
uniform float scale = 1.0;</code></pre>
<p>Add the code, restart OBS, now the effect should look like this:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-perturbation.png" alt="filter halftone perturbation" /></p>
<p>It slowly starts to look like a halftone.</p>
<p><a id='reducing-the-number-of-colors' class='anchor' aria-hidden='true'></a></p>
<h3>Reducing the number of colors</h3>
<p>Until now we use a continuous luminance. The next step is to mimic a reduced number of inks on a printed paper.</p>
<p>For a given value of luminance from 0.0 to 1.0, we can multiply the value by a constant factor and then round the product to obtain a certain number of integer values. For example, with a factor of 3, we obtain the values 0, 1, 2 and 3. The we re-divide by 3 to obtain 4 luminance values with values 0.0, 0.33, 0.66 and 1.0. It can be generalized to <em>n</em> colors by multiplying/dividing by <em>n-1</em>.</p>
<p>The computation is really simple to implement. We start by adding a global uniform number of color levels with other uniform variables at the top of the HLSL effect file:</p>
<pre><code class="language-HLSL">uniform int number_of_color_levels = 4.0;</code></pre>
<p>And we add a single line in the pixel shader, just before the gamma encoding:</p>
<pre><code class="language-HLSL">    result = round((number_of_color_levels-1)*result)/(number_of_color_levels-1);</code></pre>
<p>Add the code, restart OBS, now the effect should look like this:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-4-colors.png" alt="filter halftone 4 colors" /></p>
<p>Here we are! It is nice to see what a simple cosine-based perturbation plus rounding can do. The active part of the effect is just a couple of lines long.</p>
<p>And now it is also very interesting to check how the effect behaves with different kinds of scale filtering (context menu of the source in OBS, then <em>Scale Filtering</em>).</p>
<p>First example, the scale filtering <em>Point</em> does not perform any interpolation after zoom and shows square-formed pixels:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-zoom-scale-filtering-point.png" alt="filter halftone zoom scale filtering point" /></p>
<p>Typically, as we use a periodic pattern in the effect, "aliasing" artifacts may appear if we reduce the size of the picture:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-unzoom-scale-filtering-point.png" alt="filter halftone unzoom scale filtering point" /></p>
<p>With a scale filtering set to <em>Bicubic</em>, the interpolation after scaling shows anti-aliasing:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-zoom-scale-filtering-bicubic.png" alt="filter halftone zoom scale filtering bicubic" /></p>
<p>With reduced size, the aliasing is not completely gone but at least reduced:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-unzoom-scale-filtering-bicubic.png" alt="filter halftone unzoom scale filtering bicubic" /></p>
<p>Now a very interesting effect appears when the scale filtering is set to <em>Disable</em> on a strongly zoomed picture (attention it may not work if other filters are in the chain of the source). The pixel shader renders directly to the screen (the output is not rendered into an intermediate texture for later scaling), so it is called for every single pixel in the screen space, at a sub-pixel level for the source picture. As we use continuous mathematical functions, and sample the source picture using a <code>Linear</code> interpolation with <code>linear_clamp</code>,  the curves drawn by the pixel shader hide completely the pixel grid of the source picture. It looks like a vector drawing:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-zoom-scale-filtering-disable.png" alt="filter halftone zoom scale filtering disable" /></p>
<p>With reduced size it still behaves well:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-unzoom-scale-filtering-disable.png" alt="filter halftone unzoom scale filtering disable" /></p>
<p>The cosine-based halftone effect is completely implemented now. It has many parameters set with default values but the user cannot set these parameters so far.</p>
<p><a id='adding-properties' class='anchor' aria-hidden='true'></a></p>
<h3>Adding properties</h3>
<p>The effect is already satisfactory, we now want to improve the user experience by creating properties for the uniform variables that we already have in the effect file:<code>gamma</code>,  <code>gamma_shift</code>, <code>amplitude</code>, <code>scale</code> and <code>number_of_color_levels</code>.</p>
<p>By convention, we will name all instances of the variables or properties with the sames names as in the effect file, i.e. for the effect parameters, the data settings and the variables of the <code>data</code> structure.</p>
<p>Similarly to what is described in the Source Shake tutorial, we first have to define default values in <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_info.get_defaults"><code>source_info.get_defaults</code></a>. Default values are chosen such that applying them to a new source would give a reasonable result:</p>
<pre><code class="language-Lua">-- Sets the default settings for this source
source_info.get_defaults = function(settings)
  obs.obs_data_set_default_double(settings, "gamma", 1.0)
  obs.obs_data_set_default_double(settings, "gamma_shift", 0.0)
  obs.obs_data_set_default_double(settings, "scale", 1.0)
  obs.obs_data_set_default_double(settings, "amplitude", 0.2)
  obs.obs_data_set_default_int(settings, "number_of_color_levels", 4)
end</code></pre>
<p>Then we define the properties as sliders in <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_info.get_properties"><code>source_info.get_properties</code></a>, which builds and returns a properties structure:</p>
<pre><code class="language-Lua">-- Gets the property information of this source
source_info.get_properties = function(data)
  local props = obs.obs_properties_create()
  obs.obs_properties_add_float_slider(props, "gamma", "Gamma encoding exponent", 1.0, 2.2, 0.2)
  obs.obs_properties_add_float_slider(props, "gamma_shift", "Gamma shift", -2.0, 2.0, 0.01)
  obs.obs_properties_add_float_slider(props, "scale", "Pattern scale", 0.01, 10.0, 0.01)
  obs.obs_properties_add_float_slider(props, "amplitude", "Perturbation amplitude", 0.0, 2.0, 0.01)
  obs.obs_properties_add_int_slider(props, "number_of_color_levels", "Number of color levels", 2, 10, 1)

  return props
end</code></pre>
<p>Once a property is changed, the <a href="https://obsproject.com/docs/reference-sources.html#c.obs_source_info.update"><code>source_info.update</code></a> function is called. This is where we will transfer the values from data settings to the <code>data</code> structure used to hold values until they are set in the shader:</p>
<pre><code class="language-Lua">-- Updates the internal data for this source upon settings change
source_info.update = function(data, settings)
  data.gamma = obs.obs_data_get_double(settings, "gamma")
  data.gamma_shift = obs.obs_data_get_double(settings, "gamma_shift")
  data.scale = obs.obs_data_get_double(settings, "scale")
  data.amplitude = obs.obs_data_get_double(settings, "amplitude")
  data.number_of_color_levels = obs.obs_data_get_int(settings, "number_of_color_levels")
end</code></pre>
<p>Next, like for <code>width</code> and <code>height</code>, we need to store the effect parameters and we call once <code>source_info.update</code> to initialize the members of the <code>data</code> structure (do not forget it, otherwise OBS will try to use non-initialized data in <code>source_info.video_render</code> and log errors every frame). This block comes at the end of the <code>source_info.create</code> function just above <code>return data</code>:</p>
<pre><code class="language-Lua">  data.params.gamma = obs.gs_effect_get_param_by_name(data.effect, "gamma")
  data.params.gamma_shift = obs.gs_effect_get_param_by_name(data.effect, "gamma_shift")
  data.params.amplitude = obs.gs_effect_get_param_by_name(data.effect, "amplitude")
  data.params.scale = obs.gs_effect_get_param_by_name(data.effect, "scale")
  data.params.number_of_color_levels = obs.gs_effect_get_param_by_name(data.effect, "number_of_color_levels")


  -- Calls update to initialize the rest of the properties-managed settings
  source_info.update(data, settings)</code></pre>
<p>And finally we transfer the values from the <code>data</code> structure into the effect parameters in <code>source_info.video_render</code>:</p>
<pre><code class="language-Lua">  obs.gs_effect_set_float(data.params.gamma, data.gamma)
  obs.gs_effect_set_float(data.params.gamma_shift, data.gamma_shift)
  obs.gs_effect_set_float(data.params.amplitude, data.amplitude)
  obs.gs_effect_set_float(data.params.scale, data.scale)
  obs.gs_effect_set_int(data.params.number_of_color_levels, data.number_of_color_levels)</code></pre>
<p>Well, that's a lot. Each variable appears 7 times in different forms! Every line above is somehow needed such that OBS manages the persistency of settings, default values, display of properties, etc. Let's say it is worth the pain but it calls for a proper object-oriented design to avoid writing so many times the same lines of code.</p>
<p>Add the pieces of code, restart OBS, open the <em>Filters</em> of the source, it should look like this (here in 2 colors):</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-properties.png" alt="filter halftone properties" /></p>
<p>Playing with the parameters of a video filter and seeing the result immediately is quite satisfying. Note the aliasing effects on the preview in the <em>Filters</em> window (unclear if it is possible to change the filtering there).</p>
<p>The old-fashioned newspaper effect  is very convincing with 2 colors:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-sparrow.png" alt="filter halftone sparrow" /></p>
<p>Note that some edges are preserved on the picture so it is probably not the same result as an optical process would produce.</p>
<p>Pictures in just 3 colors can be fascinating:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena.png" alt="filter halftone lena" /></p>
<p>The first part of the tutorial is completed and the script plus its effect file are definitely a good starting point for further development. The complete <a href="https://obsproject.com/wiki/Scripting-Tutorial-Halftone-Filter-Listing">source code of this first part</a> is available.</p>
<p><a id='second-part---dithering-with-texture' class='anchor' aria-hidden='true'></a></p>
<h2>Second part - Dithering with texture</h2>
<p>In this second part we will see how to use additional textures for the pattern and the color palette.</p>
<p><a id='some-colors-please' class='anchor' aria-hidden='true'></a></p>
<h3>Some colors please</h3>
<p>If you followed the tutorial up to this point, then you are certainly fed up with the black and white pictures!</p>
<p>We change only one line in the pixel shader:</p>
<pre><code class="language-HLSL">    float3 result = linear_color + perturbation;</code></pre>
<p>And this is the result after re-starting OBS:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-colors.png" alt="filter halftone colors" /></p>
<p>It works! And it is another example of the great versatility of the HLSL language. Here we add the <code>float perturbation</code> scalar to the <code>float3 linear_color</code> (instead of the <code>float luminance</code>). HLSL makes the necessary casting transparently (i.e. converts <code>perturbation</code> to a <code>float3</code>).</p>
<p>So we add a small perturbation to the Red, Green and Blue channels. Then the color quantization is done on each channel by the <code>round</code> operation, which results in a palette of 64 colors.</p>
<p>The scalar cosine formula gives great results and has an undeniable style, but it shows as well the limit of the method. Rather than a mix of dots with different colors, as a magnified printed photo would look like, we observe a grid of uniform color tones:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena-colors.png" alt="filter halftone lena colors" /></p>
<p>When the number of color levels is reduced to 2, i.e. with 8 colors (black, white, red, green, blue, cyan, magenta, yellow), the scale factor of the perturbation can be reduced as well to obtain a picture reproducing the original colors (here with a scale filtering set to bicubic to show the single pixels):</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena-reduced-colors.png" alt="filter halftone lena reduced colors" /></p>
<p>Not bad with 8 colors and the primitive approach! But the typical "printed paper effect" cannot be reached with the current cosine-based scalar perturbation, it needs to have different values on each RGB channel. To make the perturbation fully flexible we will replace the computed formula with a pre-computed bitmap texture.</p>
<p><a id='re-factoring-the-pixel-shader' class='anchor' aria-hidden='true'></a></p>
<h3>Re-factoring the pixel shader</h3>
<p>The general method to obtain our effect can be divided in simple steps:</p>
<ol>
<li>The color of the source pixel is retrieved from the <code>image</code> texture and gamma-decoded</li>
<li>A variable perturbation is determined according to the position of the source pixel</li>
<li>The perturbation is added to the RGB channels of the decoded source color</li>
<li>A color close to the perturbed color is selected among a limited set through the rounding operation</li>
<li>The close color is gamma-encoded and returned as output</li>
</ol>
<p>First, to be very general, we will add a variable <code>offset</code> set to 0 by default at step 3:</p>
<p>_perturbed_color = linear<em>color + offset + amplitude*perturbation</em></p>
<p>In addition, we allow the <code>amplitude</code> to be negative. So first, in the Lua file, we change the definition of the amplitude property (<code>-2.0</code> as lower bound):</p>
<pre><code class="language-Lua">  obs.obs_properties_add_float_slider(props, "amplitude", "Perturbation amplitude", -2.0, 2.0, 0.01)</code></pre>
<p>And in the effect file we need an additional uniform value at the top of file:</p>
<pre><code class="language-HLSL">uniform float offset = 0.0;</code></pre>
<p>Second, and this is the main change, the steps 2 and 4 are put into separate functions for better modularity. We will even define the "perturbation color" (determined at step 2) and the closest color (determined as step 4) with an additional alpha, i.e. both are defined as <code>float4</code>. The variable alpha channel will be treated later on, for now the exact same functionality will be implemented with alpha set to 1.0.</p>
<p>Replace the pixel shader with the 2 new functions and the new code for the pixel shader in the effect file:</p>
<pre><code class="language-HLSL">float4 get_perturbation(float2 position)
{
    float4 result;
    result = float4((cos(PI*position.x/scale/4.0) * cos(PI*position.y/scale/4.0)).xxx, 1.0);
    return result;
}

float4 get_closest_color(float3 input_color)
{
    float4 result;
    result = float4(round((number_of_color_levels-1)*input_color)/(number_of_color_levels-1), 1.0);
    return result;
}

float4 pixel_shader_halftone(pixel_data pixel) : TARGET
{
    float4 source_sample = image.Sample(linear_clamp, pixel.uv);
    float3 linear_color = decode_gamma(source_sample.rgb, gamma, gamma_shift);

    float2 position = pixel.uv * float2(width, height);
    float4 perturbation = get_perturbation(position);

    float3 perturbed_color = linear_color + offset + amplitude*perturbation.rgb;

    float4 closest_color = get_closest_color(clamp(perturbed_color, 0.0, 1.0));

    return float4(encode_gamma(closest_color.rgb, gamma), source_sample.a);
}</code></pre>
<p>Add the code, restart OBS, no change is expected. Even if the <code>amplitude</code> is set to a negative value, the output is similar due to the symmetric cosine formula.</p>
<p><a id='adding-the-texture-properties' class='anchor' aria-hidden='true'></a></p>
<h3>Adding the texture properties</h3>
<p>Two textures will be added:</p>
<ul>
<li>A seamless pattern texture to replace the cosine formula by an arbitrary bitmap-based perturbation</li>
<li>A palette texture to retrieve colors from a limited set and hence replace the rounding operation</li>
</ul>
<p>The basis for managing a texture is a <a href="https://obsproject.com/docs/reference-libobs-graphics-image-file.html#c.gs_image_file"><code>gs_image_file</code></a> object. It is selected as a file by the user.</p>
<p>We need some additional variables to manage the texture:</p>
<ul>
<li>Obviously we need the <code>texture2d</code> objects (re-defined as <code>Texture2D</code> type by a macro to be more HLSL compliant)</li>
<li>We define the sizes of the textures (not available through the <code>Texture2D</code> definition)</li>
<li>And we define an alpha encoding/decoding exponent just in case</li>
</ul>
<p>To start the definition, add the following uniform variables at the top of the effect file:</p>
<pre><code class="language-HLSL">// Pattern texture
uniform Texture2D pattern_texture;
uniform float2 pattern_size = {-1.0, -1.0};
uniform float pattern_gamma = 1.0;

// Palette texture
uniform Texture2D palette_texture;
uniform float2 palette_size = {-1.0, -1.0};
uniform float palette_gamma = 1.0;</code></pre>
<p>Coming to the Lua file, we will use the opportunity to add the new <code>offset</code> used in the perturbation calculation (see previous section). Add the retrieval of effect parameters to the <code>source_info.create</code> function:</p>
<pre><code class="language-Lua">  data.params.offset = obs.gs_effect_get_param_by_name(data.effect, "offset")

  data.params.pattern_texture = obs.gs_effect_get_param_by_name(data.effect, "pattern_texture")
  data.params.pattern_size = obs.gs_effect_get_param_by_name(data.effect, "pattern_size")
  data.params.pattern_gamma = obs.gs_effect_get_param_by_name(data.effect, "pattern_gamma")

  data.params.palette_texture = obs.gs_effect_get_param_by_name(data.effect, "palette_texture")
  data.params.palette_size = obs.gs_effect_get_param_by_name(data.effect, "palette_size")
  data.params.palette_gamma = obs.gs_effect_get_param_by_name(data.effect, "palette_gamma")</code></pre>
<p>The next addition is a helper function to set the size and texture effect parameters according to a simple logic, i.e. if the texture object is <code>nil</code>, then its size is set to <em>(-1,-1)</em> such that the shader is able to recognize it (and note the use of the <a href="https://obsproject.com/docs/reference-libobs-graphics-vec2.html"><code>vec2</code></a> OBS object):</p>
<pre><code class="language-Lua">function set_texture_effect_parameters(image, param_texture, param_size)
  local size = obs.vec2()
  if image then
    obs.gs_effect_set_texture(param_texture, image.texture)
    obs.vec2_set(size, image.cx, image.cy)
  else
    obs.vec2_set(size, -1, -1)
  end
  obs.gs_effect_set_vec2(param_size, size)
end</code></pre>
<p>The helper function is used in the <code>source_info.video_render</code> function, assuming the related image file objects representing the pattern and palette textures are stored in the <code>data</code> variable passed by OBS:</p>
<pre><code class="language-Lua">  obs.gs_effect_set_float(data.params.offset, data.offset)

  -- Pattern texture
  set_texture_effect_parameters(data.pattern, data.params.pattern_texture, data.params.pattern_size)
  obs.gs_effect_set_float(data.params.pattern_gamma, data.pattern_gamma)

  -- Palette texture
  set_texture_effect_parameters(data.palette, data.params.palette_texture, data.params.palette_size)
  obs.gs_effect_set_float(data.params.palette_gamma, data.palette_gamma)</code></pre>
<p>We continue to implement the textures with default values. Note that the properties set by the user, and kept in the user settings, are paths to the texture files (empty if no texture is selected). Add the following lines in the <code>source_info.get_defaults</code> function:</p>
<pre><code class="language-Lua">  obs.obs_data_set_default_double(settings, "offset", 0.0)

  obs.obs_data_set_default_string(settings, "pattern_path", "")
  obs.obs_data_set_default_double(settings, "pattern_gamma", 1.0)
  obs.obs_data_set_default_string(settings, "palette_path", "")
  obs.obs_data_set_default_double(settings, "palette_gamma", 1.0)</code></pre>
<p>For the properties, the function <a href="https://obsproject.com/docs/reference-properties.html#c.obs_properties_add_path"><code>obs.obs_properties_add_path</code></a> is used to let the user select a path. Because we want to be able to fallback to a formula (without texture), we foresee a button for each texture to reset the path to an empty string (with an inline function that returns <code>true</code> to force the refresh of the properties widget and uses a kept reference in <code>data.settings</code>, see below). Add the following lines in <code>source_info.get_properties</code>:</p>
<pre><code class="language-Lua">  obs.obs_properties_add_float_slider(props, "offset", "Perturbation offset", -2.0, 2.0, 0.01)

  obs.obs_properties_add_path(props, "pattern_path", "Pattern path", obs.OBS_PATH_FILE,
                              "Picture (*.png *.bmp *.jpg *.gif)", nil)
  obs.obs_properties_add_float_slider(props, "pattern_gamma", "Pattern gamma exponent", 1.0, 2.2, 0.2)
  obs.obs_properties_add_button(props, "pattern_reset", "Reset pattern", function()
    obs.obs_data_set_string(data.settings, "pattern_path", ""); data.pattern = nil; return true; end)

  obs.obs_properties_add_path(props, "palette_path", "Palette path", obs.OBS_PATH_FILE,
                              "Picture (*.png *.bmp *.jpg *.gif)", nil)
  obs.obs_properties_add_float_slider(props, "palette_gamma", "Palette gamma exponent", 1.0, 2.2, 0.2)
  obs.obs_properties_add_button(props, "palette_reset", "Reset palette", function()
     obs.obs_data_set_string(data.settings, "palette_path", ""); data.palette = nil; return true; end)</code></pre>
<p>Another helper function is added to manage the reading of the image file, the initialization of the texture inside, an the freeing of allocated memory when necessary. Note that this is only possible in the graphics thread (this is the reason for the call to <code>obs_enter_graphics</code>), and that the function <code>gs_image_file_init_texture</code> is separated from reading the image:</p>
<pre><code class="language-Lua">-- Returns new texture and free current texture if loaded
function load_texture(path, current_texture)

  obs.obs_enter_graphics()

  -- Free any existing image
  if current_texture then
    obs.gs_image_file_free(current_texture)
  end

  -- Loads and inits image for texture
  local new_texture = nil
  if string.len(path) &gt; 0 then
    new_texture = obs.gs_image_file()
    obs.gs_image_file_init(new_texture, path)
    if new_texture.loaded then
      obs.gs_image_file_init_texture(new_texture)
    else
      obs.blog(obs.LOG_ERROR, "Cannot load image " .. path)
      obs.gs_image_file_free(current_texture)
      new_texture = nil
    end
  end

  obs.obs_leave_graphics()
  return new_texture
end</code></pre>
<p>Finally, reading the image files is triggered in the <code>update</code> function, i.e. when a data settings was changed by the user or at OBS startup. Special variables are defined to keep the path of an image file previously loaded, such that it can be freed when another file needs to be loaded. Note that it is necessary to keep a reference in <code>data.settings</code> for the inline callback functions of the buttons:</p>
<pre><code class="language-Lua">  -- Keeps a reference on the settings
  data.settings = settings

  data.offset = obs.obs_data_get_double(settings, "offset")

  local pattern_path = obs.obs_data_get_string(settings, "pattern_path")
  if data.loaded_pattern_path ~= pattern_path then
    data.pattern = load_texture(pattern_path, data.pattern)
    data.loaded_pattern_path = pattern_path
  end
  data.pattern_gamma = obs.obs_data_get_double(settings, "pattern_gamma")

  local palette_path = obs.obs_data_get_string(settings, "palette_path")
  if data.loaded_palette_path ~= palette_path then
    data.palette = load_texture(palette_path, data.palette)
    data.loaded_palette_path = palette_path
  end
  data.palette_gamma = obs.obs_data_get_double(settings, "palette_gamma")</code></pre>
<p>After adding the code, restart OBS and the properties should appear in the <em>Filters</em> dialog window:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-properties-textures.png" alt="filter halftone properties textures" /></p>
<p>The pattern and palette textures are not yet functional.</p>
<p><a id='bitmap-based-dithering-with-seamless-patterns' class='anchor' aria-hidden='true'></a></p>
<h3>Bitmap-based dithering with seamless patterns</h3>
<p>The naive algorithm we use is actually a form of <a href="https://en.wikipedia.org/wiki/Ordered_dithering">ordered dithering</a>, that typically relies on a "Bayer matrix" tiled over the picture, where each number from the matrix is added to the color of the related pixel, and the closest color is determined. In average, the mix of neighbor color dots reproduces the original color. Note that we keep this simple algorithm, while <a href="https://bisqwit.iki.fi/story/howto/dither/jy">other algorithms for dithering with an arbitrary palette</a> exist.</p>
<p>In its mathematical form, a Bayer matrix contain levels between 0 and 1 distributed over the matrix area. Bayer matrices can be represented as well as bitmap images with gray scales, like in this <a href="https://github.com/tromero/BayerMatrix/tree/master/images">repository of Bayer PNG textures</a>.</p>
<p>The picture of the basic 2x2 Bayer matrix is a square of 2 pixels by 2 pixels, what make a really tiny image:</p>
<p><em>Bayer matrix texture with 4 levels:</em> :arrow_right: <img src="https://obsproject.com/wiki/images/scripting/filter-halftone-bayer-2x2.png" alt="filter halftone bayer 2x2" /> :arrow_left:</p>
<p>After a zoom:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-bayer-2x2-big.png" alt="filter halftone bayer 2x2 big" /></p>
<p>Please note the 4 gray levels 0, 1/4, 2/4, 3/4 increasing along a loop like the "alpha" greek letter (top-right then bottom-left then top-left then bottom-right). This construction ensures that the pattern can be tiled infinitely in each direction without visible border artifact.</p>
<p>Bayer matrices of higher orders can be constructed recursively by replacing each pixel by the whole matrix and adding the levels. As an example, for a 4x4 matrix starting from the 2x2 matrix, the top-right pixel (level 0 pure black) is replaced directly with the 2x2 matrix, then the bottom right pixel (level 1/4) becomes the 2x2 matrix with 1/4 added to the levels of the 2x2 matrix, etc. At the end, the 4x4 Bayer matrix looks like (note the top-right 2x2 block, which is the same as the 2x2 Bayer matrix):</p>
<p><em>Bayer matrix texture with 16 levels:</em> :arrow_right: <img src="https://obsproject.com/wiki/images/scripting/filter-halftone-bayer-4x4.png" alt="filter halftone bayer 4x4" /> :arrow_left:</p>
<p>After a zoom:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-bayer-4x4-big.png" alt="filter halftone bayer 4x4 big" /></p>
<p>An interesting variation with Bayer matrices is to <a href="http://caca.zoy.org/wiki/libcaca/study/2">use a non-rectangular shape</a> itself arranged to make a seamless pattern. For example with a cross of 5 pixels (hence 5 levels), arranged with no holes, resulting in a minimal 5x5 matrix:</p>
<p><em>Bayer matrix texture with 5 levels:</em> :arrow_right: <img src="https://obsproject.com/wiki/images/scripting/filter-halftone-bayer-cross-5-levels.png" alt="filter halftone bayer cross 5 levels" /> :arrow_left:</p>
<p>After a zoom:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-bayer-cross-5-levels-big.png" alt="filter halftone bayer cross 5 levels big" /></p>
<p>Now we have some patterns to play with, time to modify the effect file.</p>
<p>Usually, in order to find coordinates in a tiled pattern, given the coordinates in the full area, the solution would be to use a <a href="https://en.wikipedia.org/wiki/Modulo_operation">"modulo" operation</a> (remainder of the division by the size of the pattern). Here we will just let the GPU do it for us by using a <a href="https://docs.microsoft.com/en-us/windows/uwp/graphics-concepts/texture-addressing-modes#wrap-texture-address-mode">"wrap" texture address mode</a>. A new <code>sampler_state</code> (redefined as <code>SamplerState</code> by macro to be more HLSL compliant) is defined for that in the effect file:</p>
<pre><code class="language-HLSL">SamplerState linear_wrap
{
    Filter    = Linear; 
    AddressU  = Wrap;
    AddressV  = Wrap;
};</code></pre>
<p>With this definition, we re-define the function <code>get_perturbation</code>:</p>
<pre><code class="language-HLSL">float4 get_perturbation(float2 position)
{
    if (pattern_size.x&gt;0)
    {
        float2 pattern_uv = position / pattern_size;
        float4 pattern_sample = pattern_texture.Sample(linear_wrap, pattern_uv / scale);
        float3 linear_color = decode_gamma(pattern_sample.rgb, pattern_gamma, 0.0);
        return float4(2.0*(linear_color-0.5), pattern_sample.a);
    }
    else
        return float4((cos(PI*position.x/scale/4.0) * cos(PI*position.y/scale/4.0)).xxx, 1.0);
}</code></pre>
<p>Please note that:</p>
<ul>
<li>If the X size of the pattern is negative, i.e. if no pattern file was selected by the user or the file could not be loaded, then the function falls back to the cosine formula.</li>
<li>It is necessary to compute UV coordinates in <code>pattern_uv</code> to locate the pixel in the pattern texture, given by <code>position / pattern_size</code>, but because <code>position</code> (pixel coordinates in the source picture) has values bigger than <code>pattern_size</code>, the resulting UV coordinates has values between 0.0 and much more than 1.0, and that is where the "Wrap" mode is important.</li>
<li>The function is expected to return RGB values from -1.0 to 1.0, that is why there is a normalization as <code>2.0*(linear_color-0.5)</code></li>
<li>Using a "Linear" sampling (as in <code>linear_wrap</code>) is an arbitrary choice here, and means that if the pattern is scaled, colors from the pattern are interpolated (maybe not the expectation with a Bayer matrix). A "Point" filter could be used too, depending on the kind of scaling that is desired, in conjunction with the <em>Scale Filtering</em> setting.</li>
</ul>
<p>Add the code, restart OBS, then download and select the 4x4 Bayer matrix above (the tiny one), set the scale to 1.0, the <em>Scale Filtering</em> to <em>Bicubic</em> and you should obtain something like this with 2 color levels:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena-bayer-4x4.png" alt="filter halftone lena bayer 4x4" /></p>
<p>Such an image may bring back memories of the 8-bits or 16-bits computer era, depending how old you are, this is almost pixel-art!</p>
<p>The texture based on the cross-formed pattern with 5 levels gives a quite different style to the dithering:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena-bayer-cross-5-levels.png" alt="filter halftone lena bayer cross 5 levels" /></p>
<p><a id='creating-seamless-patterns' class='anchor' aria-hidden='true'></a></p>
<h3>Creating seamless patterns</h3>
<p>The effect is now strongly driven by the pattern used as input. A "seamless" pattern is necessary and it is not trivial to create one. There are special tools around to do that, or there is a quite simple method that works with any paint tool (e.g. paint.net).</p>
<p>Actually, the issue here is that any global transformation applied to a complete picture (e.g. gaussian blur) would assume that the outside of the picture has a constant color (e.g. white), and would produce border artifacts that are only visible when the picture is tiled.</p>
<p>The simple method to avoid this is to "pre-tile" the picture on a 9x9 grid, then apply the global transformation, then select and crop the central part of the picture. This way the border artifacts are limited to the surrounding pictures and the central picture can be tiled seamlessly:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-seamless-pattern.png" alt="filter halftone seamless pattern" /></p>
<p>Using a blur filter just creates the different levels expected in a dithering pattern. This is the resulting star pattern:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-pattern-star-blur.png" alt="filter halftone pattern star blur" /></p>
<p>The filtered picture shows stars with different sizes, that correspond the the different levels created by the blur operation (a better effect would be reached with more blurring in the pattern, do your own experimentation):</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena-stars.png" alt="filter halftone lena stars" /></p>
<p>The same kind of technique was used to blur a texture from the <a href="https://en.wikipedia.org/wiki/Hexagonal_tiling">hexagonal tiling</a> page on Wikipedia:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-pattern-hexagons-blur.png" alt="filter halftone pattern hexagons blur" /></p>
<p>On this pattern the RGB channels are separated. The blurring was done in one operation that kept the RGB separation. The result brings us back to producing a halftone picture, this time with colors. Look at the many little discs of different sizes, resulting from blurring the hexagons in the texture:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena-eyes-hexagons-blur.png" alt="filter halftone lena eyes hexagons blur" /></p>
<p>Finally, another method to produce a nice pattern is just to compute it and grab it as a screenshot. As an example, this <a href="http://glslsandbox.com/e#71491.0">shader on GLSL sandbox</a> was used to produce this pattern, which kind of reproduces the shape of printed paper, i.e. with an orthogonal raster for each RGB, and an orientation of 0° for Red, 30° for Green, 60° for Blue (the pattern repeats after 30 oscillations, this is why the picture is so big):</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-pattern-print-raster.png" alt="filter halftone pattern print raster" /></p>
<p>The resulting picture is very similar to the one produced with the blurred hexagons:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-lena-eyes-print-raster.png" alt="filter halftone lena eyes print raster" /></p>
<p>Actually printed paper uses a CMYK color model (Cyan-Magenta-Yellow-Black) with a subtractive blend mode, and our simple approach is classically additive with the RGB components. The real computation with CMYK would require a modification of the perturbation formula. Nevertheless this simple computation produces vary convincing results to reproduce the style of printed paper. This is especially true for comics or pop art (after tweaking the amplitude and offset):</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-pop-art.png" alt="filter halftone pattern pop art" /></p>
<p>Even if our filter does not produce the typical CMYK print raster, it works very well in 8 colors because mixing the primary colors Red, Green and Blue with an additive blend gives directly the primary colors of a subtractive blend Cyan (Green+Blue), Magenta (Red+Blue) and Yellow (Red+Green). At the end, the resulting set of colors is the same with additive RGB or subtractive CMYK, and this is why the general impression produced by the output of the filter reminds printed paper.</p>
<p><a id='arbitrary-palette' class='anchor' aria-hidden='true'></a></p>
<h3>Arbitrary palette</h3>
<p>Until now the color quantization is based on finding the closest discrete level on each RGB component. The operation is simple and quick.</p>
<p>The goal now is to read the different colors from a texture and find the closest one. The operation will imply, for each single rendered pixel, a comparison with a potentially large number of other colors. Of course the operation will not be quick and the palette cannot be too big.</p>
<p>The web site <a href="https://lospec.com/palette-list">Lospec is a good source for palettes</a>. It proposes curated palettes with usage examples in different formats. For our filter the best is to use the one-pixel per color form, all pixels in a single row.</p>
<p>As an example, with this format, the original palette of the Gameboy would look like:</p>
<p><em>Palette of the Gameboy:</em> :arrow_right: <img src="https://obsproject.com/wiki/images/scripting/filter-halftone-palette-gameboy.png" alt="filter halftone palette gameboy" /> :arrow_left: Zoomed: <img src="https://obsproject.com/wiki/images/scripting/filter-halftone-palette-gameboy-big.png" alt="filter halftone palette gameboy big" /></p>
<p>coming to the code, first, to be sure that the colors do not get interpolated, a new sampler state using the "Point" filter is necessary in the effect file:</p>
<pre><code class="language-HLSL">SamplerState point_clamp
{
    Filter    = Point; 
    AddressU  = Clamp;
    AddressV  = Clamp;
};</code></pre>
<p>Then, the <code>get_closest_color</code> is modified to include a color search. Comparing two colors is based on a simple <code>distance</code> function. This is the same as the usual distance between 3D points, applied to the RGB components. There are many <a href="https://en.wikipedia.org/wiki/Color_difference">sophisticated color comparison methods</a>, the usual distance will be good enough for our purpose here.</p>
<p>The new function replaces <code>get_closest_color</code> in the effect file:</p>
<pre><code class="language-HLSL">float4 get_closest_color(float3 input_color)
{
    float4 result;
    if (palette_size.x&gt;0)
    {
        float min_distance = 1e10;
        float2 pixel_size = 1.0 / min(256, palette_size);
        for (float u=pixel_size.x/2.0; u 0

  obs.obs_property_set_visible(obs.obs_properties_get(props, "pattern_reset"), pattern)
  obs.obs_property_set_visible(obs.obs_properties_get(props, "pattern_gamma"), pattern)

  obs.obs_property_set_visible(obs.obs_properties_get(props, "number_of_color_levels"), not palette)
  obs.obs_property_set_visible(obs.obs_properties_get(props, "palette_reset"), palette)
  obs.obs_property_set_visible(obs.obs_properties_get(props, "palette_gamma"), palette)

  return true
end</code></pre>
<p>Then we re-defined the <code>source_info.get_properties</code> function as such, with some renaming:</p>
<pre><code class="language-Lua">-- Gets the property information of this source
source_info.get_properties = function(data)
  print("In source_info.get_properties")

  local props = obs.obs_properties_create()

  local gprops = obs.obs_properties_create()
  obs.obs_properties_add_group(props, "input", "Input Source", obs.OBS_GROUP_NORMAL, gprops)
  obs.obs_properties_add_float_slider(gprops, "gamma", "Gamma encoding exponent", 1.0, 2.2, 0.2)
  obs.obs_properties_add_float_slider(gprops, "gamma_shift", "Gamma shift", -2.0, 2.0, 0.01)

  gprops = obs.obs_properties_create()
  obs.obs_properties_add_group(props, "pattern", "Dithering Pattern", obs.OBS_GROUP_NORMAL, gprops)
  obs.obs_properties_add_float_slider(gprops, "scale", "Pattern scale", 0.01, 10.0, 0.01)
  obs.obs_properties_add_float_slider(gprops, "amplitude", "Dithering amplitude", -2.0, 2.0, 0.01)
  obs.obs_properties_add_float_slider(gprops, "offset", "Dithering luminosity shift", -2.0, 2.0, 0.01)

  local p = obs.obs_properties_add_path(gprops, "pattern_path", "Pattern texture", obs.OBS_PATH_FILE,
                              "Picture (*.png *.bmp *.jpg *.gif)", nil)
  obs.obs_property_set_modified_callback(p, set_properties_visibility)
  obs.obs_properties_add_float_slider(gprops, "pattern_gamma", "Pattern gamma exponent", 1.0, 2.2, 0.2)
  obs.obs_properties_add_button(gprops, "pattern_reset", "Reset pattern texture", function(properties, property)
    obs.obs_data_set_string(data.settings, "pattern_path", ""); data.pattern = nil;
    set_properties_visibility(properties, property, data.settings); return true; end)

  gprops = obs.obs_properties_create()
  obs.obs_properties_add_group(props, "palette", "Color palette", obs.OBS_GROUP_NORMAL, gprops)
  obs.obs_properties_add_int_slider(gprops, "number_of_color_levels", "Number of color levels", 2, 10, 1)
  p = obs.obs_properties_add_path(gprops, "palette_path", "Palette texture", obs.OBS_PATH_FILE,
                              "Picture (*.png *.bmp *.jpg *.gif)", nil)
  obs.obs_property_set_modified_callback(p, set_properties_visibility)
  obs.obs_properties_add_float_slider(gprops, "palette_gamma", "Palette gamma exponent", 1.0, 2.2, 0.2)
  obs.obs_properties_add_button(gprops, "palette_reset", "Reset palette texture", function(properties, property)
    obs.obs_data_set_string(data.settings, "palette_path", ""); data.palette = nil;
    set_properties_visibility(properties, property, data.settings); return true; end)

  return props
end</code></pre>
<p>The change with the groups is always the same: first a new <code>obs_properties</code> object is created, and added to the main <code>obs_properties</code> object, then the new properties object is filled with <code>property</code> objects.</p>
<p>Add the code, reload the script, the properties should now be displayed in named groups and some parameters be displayed only when necessary:</p>
<p><img src="https://obsproject.com/wiki/images/scripting/filter-halftone-final-properties.png" alt="filter halftone final properties" /></p>
<p><a id='single-file-delivery' class='anchor' aria-hidden='true'></a></p>
<h3>Single file delivery</h3>
<p>Final operation on this script, we want to provide a single Lua file to ease deployment. OBS features the <a href="https://obsproject.com/docs/reference-libobs-graphics-effects.html#c.gs_effect_create"><code>gs_effect_create</code></a> function to compile an effect as a string and not as a file.</p>
<p>First we need to copy the complete content of the effect file into one big string:</p>
<pre><code class="language-Lua">EFFECT = [[

// !! Copy the code of the effect file here !!

]]</code></pre>
<p>Then change the compilation in <code>source_info.create</code> to (note that the second parameter is supposed to be some file name and cannot be <code>nil</code>, the value may be used for error messages):</p>
<pre><code class="language-Lua">  data.effect = obs.gs_effect_create(EFFECT, "halftone_effect_code", nil)</code></pre>
<p>And modify the error message line to remove the mention of the effect file path:</p>
<pre><code class="language-Lua">    obs.blog(obs.LOG_ERROR, "Effect compilation failed")</code></pre>
<p>No visible effect normally with this change. Just a matter of putting everything in one file.</p>
<p><a id='conclusion' class='anchor' aria-hidden='true'></a></p>
<h2>Conclusion</h2>
<p>Woow that was a long tutorial!! The <a href="https://obsproject.com/wiki/Scripting-Tutorial-Halftone-Filter-Listing">code of the second part</a> is as well available.</p>
<p>Many aspects were covered, from writing shaders and Lua scripts to video processing basics. The most incredible thing is the simplicity of the basis algorithm and the effects it produces.</p>
<p>There is still room for further experiments: real CMYK transformation, better color comparison, transparency effects, seamless patterns design, etc. This is left as exercise for the reader!</p>
<p>That's all folks!</p>
		&nbsp;

	</div>

	<div class="wiki_sidebar">

		<h1><a href="https://obsproject.com/wiki/Home">Home</a></h1>
<h1><a href="https://obsproject.com/wiki/install-instructions">Install instructions</a></h1>
<ul>
<li><a href="https://obsproject.com/wiki/install-instructions#windows">Windows</a></li>
<li><a href="https://obsproject.com/wiki/install-instructions#macos">macOS</a></li>
<li><a href="https://obsproject.com/wiki/install-instructions#linux">Linux</a></li>
<li><a href="https://obsproject.com/wiki/install-instructions#freebsd">FreeBSD</a></li>
</ul>
<h1><a href="https://obsproject.com/wiki/Building-OBS-Studio">Build instructions</a></h1>
<ul>
<li><a href="https://obsproject.com/wiki/Build-Instructions-For-Windows">Windows</a></li>
<li><a href="https://obsproject.com/wiki/Build-Instructions-For-Mac">macOS</a></li>
<li><a href="https://obsproject.com/wiki/Build-Instructions-For-Linux">Linux</a></li>
<li><a href="https://obsproject.com/wiki/Build-Instructions-For-FreeBSD">FreeBSD</a></li>
</ul>
<h1>Development &amp; Scripting</h1>
<ul>
<li><a href="https://obsproject.com/wiki/Getting-Started-with-OBS-Studio-Development">Getting Started with OBS Studio Development</a></li>
<li><a href="https://obsproject.com/wiki/Getting-Started-With-OBS-Scripting">Getting Started With OBS Scripting</a><ul>
<li><a href="https://obsproject.com/wiki/Scripting-Tutorial-Source-Shake">Scripting Tutorial: Source Shake</a></li>
<li><a href="https://obsproject.com/wiki/Scripting-Tutorial-Halftone-Filter">Scripting Tutorial: Halftone Filter</a></li>
</ul>
</li>
<li><a href="https://obsproject.com/wiki/Service-Submission-Guidelines">Service Submission Guidelines</a></li>
</ul>
	</div>

</div>

  <div class="footer_push"></div>
</div>
<!-- End Wrapper -->
  
  <footer id="footer" class="footer cf">
    <div class="footer_extra">
      <div class="footer_left">
        <div class="footer_row">
          <div class="logo"><img src="https://obsproject.com/assets/images/new_icon_small-r.png"></div>
          <div class="footer_title">OBS Project</div>
        </div>
        <div class="footer_row footer_social">
          <a href="https://twitter.com/OBSProject" target="_blank" aria-label="OBS Twitter">
            <i class="icon-twitter"></i>
          </a>
          <a href="https://facebook.com/OpenBroadcasterSoftware" target="_blank" aria-label="OBS Facebook">
            <i class="icon-facebook"></i>
          </a>
          <a href="https://obsproject.com/discord" target="_blank" aria-label="OBS Discord">
            <img src="https://obsproject.com/assets/images/Discord.svg" class="icon-discord">
          </a>
          <a href="https://github.com/obsproject/obs-studio" target="_blank" aria-label="OBS GitHub">
            <i class="icon-github"></i>
          </a>
        </div>
      </div>
      <div class="footer_right">

        <!-- App -->
        <div class="footer_items"><div class="footer_category">OBS Studio</div>
          <a href="https://obsproject.com/download" aria-label="Download">Download</a>
          <a href="https://ideas.obsproject.com/" target="_blank" aria-label="Feature suggestions">Ideas</a>
          <a href="https://obsproject.com/privacy-policy" aria-label="Privacy Policy">Privacy Policy</a>
        </div>

        <!-- Contribute -->
        <div class="footer_items"><div class="footer_category">Contribute</div>
          <a href="https://github.com/obsproject/obs-studio" target="_blank" aria-label="OBS GitHub">GitHub</a>
          <a href="https://opencollective.com/obsproject" aria-label="OBS on Open Collective">Open Collective</a>
          <a href="https://www.patreon.com/obsproject/overview" aria-label="OBS on Patreon">Patreon</a>
        </div>

        <!-- Help -->
        <div class="footer_items"><div class="footer_category">Support</div>
          <a href="https://obsproject.com/help" aria-label="Help Portal">Help Portal</a>
          <a href="https://obsproject.com/forum/" aria-label="Forums">Forums</a>
          <a href="https://obsproject.com/discord" aria-label="Official Discord">Discord</a>
          <a href="https://obsproject.com/wiki" aria-label="Support Wiki">Wiki</a>
        </div>

      </div>
    </div>

    <div class="copyright">
      <p>© 2012 - 2023. OBS and OBS Studio are created and maintained by Lain. Development by <a href="https://github.com/obsproject/OBS-studio/graphs/contributors">OBS Studio Contributors</a>.<br />
Website designed and created by <a href="https://twitter.com/Warchamp7">Warchamp7</a>, powered by <a href="https://getkirby.com/made-with-kirby-and-love">Kirby CMS</a>. Downloads powered by <a href="https://fastly.com/">Fastly</a>.</p>    </div>
    <br>
    <div class="languages" arial-label="Select Language">
    <p>
                          <a href="https://obsproject.com/cs/wiki">Čeština</a> 
                                  <a href="https://obsproject.com/da/wiki">Dansk</a> 
                                  <a href="https://obsproject.com/de/wiki">Deutsch</a> 
                                                <a href="https://obsproject.com/es/wiki">Español</a> 
                                  <a href="https://obsproject.com/eu/wiki">Euskara</a> 
                                  <a href="https://obsproject.com/fi/wiki">Suomi</a> 
                                  <a href="https://obsproject.com/fr/wiki">Français</a> 
                                  <a href="https://obsproject.com/hu/wiki">Magyar</a> 
                                  <a href="https://obsproject.com/ja/wiki">日本語</a> 
                                  <a href="https://obsproject.com/ko/wiki">한국어</a> 
                                  <a href="https://obsproject.com/pt-br/wiki">Português do Brasil</a> 
                                  <a href="https://obsproject.com/ru/wiki">ру́сский</a> 
                                  <a href="https://obsproject.com/sv/wiki">Svenska</a> 
                                  <a href="https://obsproject.com/tr/wiki">Türkçe</a> 
                                  <a href="https://obsproject.com/uk/wiki">українська</a> 
                                  <a href="https://obsproject.com/zh-cn/wiki">中文(简体)</a> 
                  </p>
    </div>

  </footer>
</body>

<!-- Mirrored from obsproject.com/wiki/Scripting-Tutorial-Halftone-Filter by HTTrack Website Copier/3.x [XR&CO'2014], Sun, 31 Dec 2023 03:57:04 GMT -->
</html>
